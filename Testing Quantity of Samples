import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from torch.utils.data import DataLoader
import random
import scipy.stats as stats
from scipy.integrate import quad

data = pd.read_excel('Mechanical_Malawi.xlsx')
X = data.iloc[ 3:299, 1:31] # .iloc for pandas
yUnfiltered = data.iloc[ 3:299, 38:46]
samples = 296
y = np.ones((samples,1))
toDelete = []

for i in range(0,samples): # cleaning data

  if X.iloc[i,3] == 'N': # clean input gables
    X.iloc[i,3] = 0

  #cleaning mortar quality
  if X.iloc[i,27] == 'Mud' or X.iloc[i,27] == 'Mud RF':
    X.iloc[i,27] = 1
  elif X.iloc[i,27] == 'Cement':
    X.iloc[i,27] = 2
  #cleaning roof quality
  if X.iloc[i,28] == 'Metallic':
    X.iloc[i,28] = 1
  elif X.iloc[i,28] == 'Thatched':
    X.iloc[i,28] = 2
    #cleaning masonry quality
  if X.iloc[i,29] == 'Fired grade 1':
    X.iloc[i,29] = 1
  elif X.iloc[i,29] == 'Fired grade 2':
    X.iloc[i,29] = 2
  elif X.iloc[i,29] == 'Fired grade 3':
    X.iloc[i,29] = 3
  elif X.iloc[i,29] == 'Unfired grade 1':
    X.iloc[i,29] = 4
  elif X.iloc[i,29] == 'Unfired grade 2':
    X.iloc[i,29] = 5
  elif X.iloc[i,29] == 'Unfired grade 3':
    X.iloc[i,29] = 6
  else:
    toDelete.append(i)


  columnIndex = 0
  finish = False

  while finish == False and columnIndex < yUnfiltered.shape[1]: #cleaning output data
    if yUnfiltered.iloc[i,columnIndex] == "Inf":
      columnIndex = columnIndex + 2
      if columnIndex >= yUnfiltered.shape[1]:
        toDelete.append(i)
        finish = True
    else:
      y[i,0] = yUnfiltered.iloc[i,columnIndex]
      finish = True
y = np.delete(y,toDelete,0)
X = X.drop(X.index[toDelete])
#X = X.drop(X.columns[[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]],axis =1) # index of columns to remove

samples = X.shape[0]
inputs = X.shape[1]

class SimpleDropoutNet(nn.Module):
    def __init__(self, input_dim, hidden_dim=32, dropout_prob=0.2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(p=dropout_prob),

            nn.Linear(hidden_dim, hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(p=dropout_prob),

            nn.Linear(hidden_dim, 1)
        )

    def forward(self, x):
        return self.net(x)

model = SimpleDropoutNet(input_dim=inputs)

# function that calcs the difference between the fragility curves for different failure probabilities
def fragility_MaxDiff(floodLevels_pred,floodLevels_Actual):
  mean_pred = np.mean(floodLevels_pred)
  standardDeviation_pred = np.std(floodLevels_pred)
  mean_Actual = np.mean(floodLevels_Actual)
  standardDeviation_Actual = np.std(floodLevels_Actual)

  minVal = min(min(floodLevels_pred),min(floodLevels_Actual))
  maxVal = max(max(floodLevels_pred),max(floodLevels_Actual))
  Failure_height = np.linspace(minVal*0.5, maxVal*1.5, 1000)

  def fragility_curve_pred(Failure_height):
    return stats.norm.cdf(Failure_height, mean_pred, standardDeviation_pred)
  def fragility_curve_actual(Failure_height):
    return stats.norm.cdf(Failure_height, mean_Actual, standardDeviation_Actual)

  #fragilityDiff = abs(fragility_curve_pred - fragility_curve_actual)
  #maxDiff = max(fragilityDiff)
  #KS = stats.ks_2samp(fragility_curve_pred,fragility_curve_actual)
  def integrand(x):
    return abs(fragility_curve_pred(x) - fragility_curve_actual(x))
  abc, error = quad(integrand, minVal, maxVal)
  return abc

stepsize = samples//20
MSE = []
MaxDiff = []
numsamples_list = []


for i in range (samples, 0,-stepsize):
  numdrop = int(samples - i)

  tempMaxDiff = []
  tempMSE = []

  for n in range(0,30):
    tempX = X.copy()
    tempY = y.copy()
    for z in range(0,numdrop):
      rand = random.randint(0,tempX.shape[0]-1)
      tempX = tempX.drop(tempX.index[rand])
      tempY = np.delete(tempY,rand,0)
    tempSamples = tempX.shape[0]


    if tempSamples > 1:
      X_train, X_test, y_train, y_test = train_test_split(tempX,tempY, train_size = 0.75, shuffle=True)
      X_test_unscaled = X_test.copy()
      # Scaling input parameters
      from sklearn.preprocessing import StandardScaler
      scaler = StandardScaler()
      X_train = scaler.fit_transform(X_train)
      X_test = scaler.transform(X_test)

      X_train = X_train.astype(np.float32)
      X_test = X_test.astype(np.float32)
      X_tr_tensor = torch.from_numpy(X_train).type(torch.float32)
      y_tr_tensor = torch.from_numpy(y_train).type(torch.float32)
      X_ts_tensor = torch.tensor(X_test,dtype=torch.float32)

      #training function:
      BATCH_SIZE = 32
      LR = 0.001
      EPOCHS = 1000
      def fit(model, BATCH_SIZE, LR, EPOCHS):
        XBatch = DataLoader(X_tr_tensor, batch_size=BATCH_SIZE, shuffle=False)
        yBatch = DataLoader(y_tr_tensor, batch_size=BATCH_SIZE, shuffle=False)
        loss_fn = nn.MSELoss() #better for continuous values
        optim = torch.optim.Adam(model.parameters(), lr = LR,betas=(0.5, 0.999), weight_decay=1e-3)
        for epoch in range(EPOCHS):
          for x_Batch, y_Batch in zip(XBatch, yBatch):
            ypred = model(x_Batch)
            loss = loss_fn(ypred, y_Batch)
            loss.backward()
            optim.step()
            optim.zero_grad()


      #running model
      fit(model, BATCH_SIZE, LR, EPOCHS) # to train it

      #testing model

      ytest_pred = model(X_ts_tensor)
      ytrain_pred = model(X_tr_tensor)

      #Getting errors
      tempMSE.append(mean_squared_error(y_test, ytest_pred.detach().numpy()))
      tempMaxDiff.append(fragility_MaxDiff(ytest_pred.detach().numpy(),y_test))

    print("Sample size {0}, Step {1} Completed".format(i,n+1))
  if tempSamples > 1:
    numsamples_list.append(tempSamples)
    MSE.append(np.mean(tempMSE))
    MaxDiff.append(np.mean(tempMaxDiff))

fig, axes = plt.subplots(1, 2, figsize=(8, 4))

axes[0].set_title('MSE for Varied Sample Size', fontsize = "small")
axes[0].set_xlabel('Sample Size')
axes[0].set_ylabel('MSE')
axes[0].plot(numsamples_list,MSE)

axes[1].set_title('Area Difference between fragility curves for Varied Sample Size', fontsize = "small")
axes[1].set_xlabel('Sample Size')
axes[1].set_ylabel('Area Difference (m)')
axes[1].plot(numsamples_list,MaxDiff)

plt.tight_layout()
plt.show()

np.set_printoptions(threshold=np.inf)
print(MSE)
print(MaxDiff)
